{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf69bb3f-94e6-4dba-92cd-ce08df117d67",
   "metadata": {},
   "source": [
    "## EZKL HUB Jupyter Notebook Demo \n",
    "\n",
    "Here we demonstrate the use of the EZKL hub in a Jupyter notebook whereby all components of the circuit are public or pre-committed to. This is the simplest case of using EZKL (proof of computation).\n",
    "\n",
    "This will be accomplished in 3 steps. \n",
    "\n",
    "1. Train the model. \n",
    "2. Define our visibility settings. \n",
    "3. Upload the model to the hub. \n",
    "\n",
    "That's it !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95613ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if notebook is in colab\n",
    "try:\n",
    "    # install ezkl\n",
    "    import google.colab\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ezkl\"])\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"onnx\"])\n",
    "\n",
    "# rely on local installation of ezkl if the notebook is not in colab\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "# here we create and (potentially train a model)\n",
    "\n",
    "# make sure you have the dependencies required here already installed\n",
    "from torch import nn\n",
    "import ezkl\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "\n",
    "# Defines the model\n",
    "# we got convs, we got relu, we got linear layers\n",
    "# What else could one want ????\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=5, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=2, out_channels=3, kernel_size=5, stride=2)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.d1 = nn.Linear(48, 48)\n",
    "        self.d2 = nn.Linear(48, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 32x1x28x28 => 32x32x26x26\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # flatten => 32 x (32*26*26)\n",
    "        x = x.flatten(start_dim = 1)\n",
    "\n",
    "        # 32 x (32*26*26) => 32x128\n",
    "        x = self.d1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # logits => 32x10\n",
    "        logits = self.d2(x)\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "circuit = MyModel()\n",
    "\n",
    "# Train the model as you like here (skipped for brevity)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37637c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join('network.onnx')\n",
    "data_path = os.path.join('input.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82db373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# After training, export to onnx (network.onnx) and create a data file (input.json)\n",
    "x = 0.1*torch.rand(1,*[1, 28, 28], requires_grad=True)\n",
    "\n",
    "# Flips the neural net into inference mode\n",
    "circuit.eval()\n",
    "\n",
    "    # Export the model\n",
    "torch.onnx.export(circuit,               # model being run\n",
    "                      x,                   # model input (or a tuple for multiple inputs)\n",
    "                      model_path,            # where to save the model (can be a file or file-like object)\n",
    "                      export_params=True,        # store the trained parameter weights inside the model file\n",
    "                      opset_version=10,          # the ONNX version to export the model to\n",
    "                      do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                      input_names = ['input'],   # the model's input names\n",
    "                      output_names = ['output'], # the model's output names\n",
    "                      dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                    'output' : {0 : 'batch_size'}})\n",
    "\n",
    "data_array = ((x).detach().numpy()).reshape([-1]).tolist()\n",
    "\n",
    "data = dict(input_data = [data_array])\n",
    "\n",
    "    # Serialize data into file:\n",
    "json.dump( data, open(data_path, 'w' ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e374a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "test_hub_name = \"samtvlabs\" #we've set this up for you, but you can create your own hub name and use that instead\n",
    "\n",
    "py_run_args = ezkl.PyRunArgs()\n",
    "py_run_args.input_visibility = \"public\"\n",
    "py_run_args.output_visibility = \"public\"\n",
    "py_run_args.param_visibility = \"private\" # private by default\n",
    "\n",
    "\n",
    "organization = ezkl.get_hub_credentials(test_hub_name)['organizations'][0]\n",
    "\n",
    "print(\"organization: \" + str(organization))\n",
    "\n",
    "# timestamped name\n",
    "name = \"model_\" + str(int(time.time()))\n",
    "\n",
    "deployed_model = ezkl.create_hub_artifact(model_path, data_path, name, organization['id'], target=\"resources\", py_run_args=py_run_args)\n",
    "\n",
    "print(\"deployed model: \" + str(deployed_model))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81201b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop every 5 seconds until status is not pending\n",
    "status = \"PENDING\"\n",
    "while status == \"PENDING\":\n",
    "    time.sleep(5)\n",
    "    get_model = ezkl.get_hub_artifact(deployed_model['id'])\n",
    "    status = get_model['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc44717",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "proof_id = ezkl.prove_hub(deployed_model['id'], data_path)\n",
    "print(\"proof id: \" + str(proof_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa6a580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop every 5 seconds until status is not pending\n",
    "status = \"PENDING\"\n",
    "while status == \"PENDING\":\n",
    "    time.sleep(5)\n",
    "    get_proof = ezkl.get_hub_proof(proof_id['id'])\n",
    "    status = get_proof['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e2f32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "proof = ezkl.get_hub_proof(proof_id['id'])\n",
    "\n",
    "print(\"proof: \" + str(proof))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
