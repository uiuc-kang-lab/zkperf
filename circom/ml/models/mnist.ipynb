{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, Dense, ReLU, Flatten, Softmax\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_train into one-hot format\n",
    "temp = []\n",
    "for i in range(len(y_train)):\n",
    "    temp.append(to_categorical(y_train[i], num_classes=10))\n",
    "y_train = np.array(temp)\n",
    "# Convert y_test into one-hot format\n",
    "temp = []\n",
    "for i in range(len(y_test)):    \n",
    "    temp.append(to_categorical(y_test[i], num_classes=10))\n",
    "y_test = np.array(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(28,28,1))\n",
    "out = Conv2D(1,3)(inputs)\n",
    "out = ReLU()(out)\n",
    "out = Flatten()(out)\n",
    "out = Dense(10, activation=None)(out)\n",
    "out = Softmax()(out)\n",
    "model = Model(inputs, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 1)         10        \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 26, 26, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 676)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                6770      \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 6,780\n",
      "Trainable params: 6,780\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['acc']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 829us/step - loss: 3.2919 - acc: 0.5537 - val_loss: 0.5674 - val_acc: 0.8258\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 1s 643us/step - loss: 0.4984 - acc: 0.8448 - val_loss: 0.4244 - val_acc: 0.8739\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 1s 664us/step - loss: 0.3538 - acc: 0.8937 - val_loss: 0.3560 - val_acc: 0.9000\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 1s 750us/step - loss: 0.3003 - acc: 0.9076 - val_loss: 0.3357 - val_acc: 0.9111\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1s 617us/step - loss: 0.2814 - acc: 0.9146 - val_loss: 0.3184 - val_acc: 0.9075\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 606us/step - loss: 0.2689 - acc: 0.9194 - val_loss: 0.3247 - val_acc: 0.9106\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 633us/step - loss: 0.2581 - acc: 0.9198 - val_loss: 0.3020 - val_acc: 0.9187\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1s 612us/step - loss: 0.2556 - acc: 0.9202 - val_loss: 0.3129 - val_acc: 0.9138\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2540 - acc: 0.9239 - val_loss: 0.3174 - val_acc: 0.9096\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 1s 798us/step - loss: 0.2494 - acc: 0.9264 - val_loss: 0.2993 - val_acc: 0.9176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x289f4aa60>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_test[0]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Model(model.input, model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-12.546714 , -11.377294 ,  -9.379934 , -11.585654 , -11.749796 ,\n",
       "        -17.505424 , -18.279175 ,  -0.4272291, -14.400676 , -10.785936 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model2.predict(X_test[[0]]) - model.weights[3].numpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_json = {\n",
    "    \"in\": X.astype(int).flatten().tolist(),\n",
    "    \"conv2d_weights\": (model.weights[0].numpy()*(10**9)).round().astype(int).flatten().tolist(),\n",
    "    \"conv2d_bias\": (model.weights[1].numpy()*(10**9)).round().astype(int).flatten().tolist(), # no need to sqaure the scaling because input was not scaled\n",
    "    \"dense_weights\":(model.weights[2].numpy()*(10**9)).round().astype(int).flatten().tolist(),\n",
    "    \"dense_bias\": np.zeros(model.weights[3].numpy().shape).tolist() # zero because we are not doing softmax in circom, just argmax\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scale': 1e-18,\n",
       " 'out': [-12.546713829040527,\n",
       "  -11.377293586730957,\n",
       "  -9.379934310913086,\n",
       "  -11.585654258728027,\n",
       "  -11.749795913696289,\n",
       "  -17.50542449951172,\n",
       "  -18.2791748046875,\n",
       "  -0.427229106426239,\n",
       "  -14.400675773620605,\n",
       "  -10.78593635559082],\n",
       " 'label': 7}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_json = {\n",
    "    \"scale\": 10**-18,\n",
    "    \"out\": y.flatten().tolist(),\n",
    "    \"label\": int(y.argmax())\n",
    "}\n",
    "out_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mnist_input.json\", \"w\") as f:\n",
    "    json.dump(in_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mnist_output.json\", \"w\") as f:\n",
    "    json.dump(out_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11280bdb37aa6bc5d4cf1e4de756386eb1f9eecd8dcdefa77636dfac7be2370d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 ('tf24')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
