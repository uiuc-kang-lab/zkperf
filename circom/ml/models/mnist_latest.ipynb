{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, AveragePooling2D, Flatten, Softmax, Dense, Lambda, BatchNormalization\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_train into one-hot format\n",
    "temp = []\n",
    "for i in range(len(y_train)):\n",
    "    temp.append(to_categorical(y_train[i], num_classes=10))\n",
    "y_train = np.array(temp)\n",
    "# Convert y_test into one-hot format\n",
    "temp = []\n",
    "for i in range(len(y_test)):    \n",
    "    temp.append(to_categorical(y_test[i], num_classes=10))\n",
    "y_test = np.array(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(28,28,1))\n",
    "out = Lambda(lambda x: x/100)(inputs)\n",
    "out = Conv2D(4, 3, use_bias=False)(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Lambda(lambda x: x**2+x)(out)\n",
    "out = AveragePooling2D()(out)\n",
    "# out = Lambda(lambda x: x*4)(out)\n",
    "out = Conv2D(8, 3, use_bias=False)(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Lambda(lambda x: x**2+x)(out)\n",
    "out = AveragePooling2D()(out)\n",
    "# out = Lambda(lambda x: x*4)(out)\n",
    "out = Flatten()(out)\n",
    "out = Dense(10, activation=None)(out)\n",
    "out = Softmax()(out)\n",
    "model = Model(inputs, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 4)         36        \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 26, 26, 4)         16        \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 26, 26, 4)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 13, 13, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 8)         288       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 11, 11, 8)         32        \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 11, 11, 8)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 5, 5, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                2010      \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,382\n",
      "Trainable params: 2,358\n",
      "Non-trainable params: 24\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=SGD(learning_rate=0.01, momentum=0.9),\n",
    "    metrics=['acc']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3031 - acc: 0.9112 - val_loss: 0.0945 - val_acc: 0.9705\n",
      "Epoch 2/15\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0758 - acc: 0.9761 - val_loss: 0.0792 - val_acc: 0.9745\n",
      "Epoch 3/15\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0610 - acc: 0.9807 - val_loss: 0.0588 - val_acc: 0.9808\n",
      "Epoch 4/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0535 - acc: 0.9837 - val_loss: 0.0513 - val_acc: 0.9837\n",
      "Epoch 5/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0502 - acc: 0.9838 - val_loss: 0.0493 - val_acc: 0.9846\n",
      "Epoch 6/15\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0445 - acc: 0.9854 - val_loss: 0.0502 - val_acc: 0.9837\n",
      "Epoch 7/15\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0428 - acc: 0.9858 - val_loss: 0.0470 - val_acc: 0.9856\n",
      "Epoch 8/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0417 - acc: 0.9866 - val_loss: 0.0653 - val_acc: 0.9800\n",
      "Epoch 9/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0401 - acc: 0.9870 - val_loss: 0.0500 - val_acc: 0.9851\n",
      "Epoch 10/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0412 - acc: 0.9883 - val_loss: 0.0537 - val_acc: 0.9843\n",
      "Epoch 11/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0348 - acc: 0.9886 - val_loss: 0.0399 - val_acc: 0.9869\n",
      "Epoch 12/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0340 - acc: 0.9893 - val_loss: 0.0430 - val_acc: 0.9860\n",
      "Epoch 13/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0339 - acc: 0.9891 - val_loss: 0.0425 - val_acc: 0.9866\n",
      "Epoch 14/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0348 - acc: 0.9879 - val_loss: 0.0485 - val_acc: 0.9846\n",
      "Epoch 15/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0336 - acc: 0.9885 - val_loss: 0.0476 - val_acc: 0.9831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2889cf1c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=15, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 28, 1), 0, 255)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_test[0]\n",
    "X.shape, X.min(), X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Model(model.input, model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -2.9271724,  -5.1743965,   4.3266096,   8.861395 , -10.59499  ,\n",
       "         -6.1087027, -14.946421 ,  20.252651 ,   1.7481048,   6.408617 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model2.predict(X_test[[0]]) - model.layers[-2].weights[1].numpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "(3, 3, 1, 4)\n",
      "(4,)\n",
      "(4,)\n",
      "(4,)\n",
      "(4,)\n",
      "(3, 3, 4, 8)\n",
      "(8,)\n",
      "(8,)\n",
      "(8,)\n",
      "(8,)\n",
      "(200, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print(len(model.weights))\n",
    "for weights in model.weights:\n",
    "    print(weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = model.layers[3].weights[0].numpy()\n",
    "beta = model.layers[3].weights[1].numpy()\n",
    "moving_mean = model.layers[3].weights[2].numpy()\n",
    "moving_var = model.layers[3].weights[3].numpy()\n",
    "epsilon = model.layers[3].epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.7930184 , 0.86564696, 0.80535203, 0.7487028 ], dtype=float32),\n",
       " array([-0.6174586,  2.336494 , -0.046653 , -1.3925927], dtype=float32))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = gamma/(moving_var+epsilon)**.5\n",
    "b1 = beta-gamma*moving_mean/(moving_var+epsilon)**.5\n",
    "a1, b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = model.layers[7].weights[0].numpy()\n",
    "beta = model.layers[7].weights[1].numpy()\n",
    "moving_mean = model.layers[7].weights[2].numpy()\n",
    "moving_var = model.layers[7].weights[3].numpy()\n",
    "epsilon = model.layers[7].epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.10420316, 0.1040957 , 0.09440491, 0.12571144, 0.12500723,\n",
       "        0.11510107, 0.10298571, 0.11865856], dtype=float32),\n",
       " array([-0.14729536,  0.84251314, -0.10289041,  0.4494599 , -0.4984228 ,\n",
       "        -0.4116003 ,  0.7156993 ,  0.08575855], dtype=float32))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2 = gamma/(moving_var+epsilon)**.5\n",
    "b2 = beta-gamma*moving_mean/(moving_var+epsilon)**.5\n",
    "a2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_json = {\n",
    "    \"in\": X.astype(int).flatten().tolist(), # X is already 100 times to begin with\n",
    "    \"conv2d_1_weights\": (model.layers[2].weights[0].numpy()*(10**2)).round().astype(int).flatten().tolist(),\n",
    "    \"conv2d_1_bias\": (np.array([0]*4)*(10**2)**2).round().astype(int).flatten().tolist(),\n",
    "    \"bn_1_a\": (a1*(10**2)).round().astype(int).flatten().tolist(),\n",
    "    \"bn_1_b\": (b1*(10**2)**3).round().astype(int).flatten().tolist(),\n",
    "    # poly layer would be (10**2)**3=10**6 times as well\n",
    "    # average pooling will scale another 10**2 times\n",
    "    \"conv2d_2_weights\": (model.layers[6].weights[0].numpy()*(10**2)).round().astype(int).flatten().tolist(),\n",
    "    \"conv2d_2_bias\": (np.array([0]*8)*((10**2)**8)).round().astype(int).flatten().tolist(),\n",
    "    \"bn_2_a\": (a2*(10**2)).round().astype(int).flatten().tolist(),\n",
    "    \"bn_2_b\": (b2*(10**2)**9).round().astype(int).flatten().tolist(),\n",
    "    # poly layer would be (10**2)**9=10**18 times as well\n",
    "    # average pooling will scale another 10**2 times\n",
    "    \"dense_weights\":(model.layers[11].weights[0].numpy()*(10**2)).round().astype(int).flatten().tolist(),\n",
    "    \"dense_bias\": np.zeros(model.layers[11].weights[1].numpy().shape).tolist() # zero because we are not doing softmax in circom, just argmax\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scale': 1e-40,\n",
       " 'out': [-2.9271724224090576,\n",
       "  -5.174396514892578,\n",
       "  4.3266096115112305,\n",
       "  8.861394882202148,\n",
       "  -10.594989776611328,\n",
       "  -6.108702659606934,\n",
       "  -14.946420669555664,\n",
       "  20.25265121459961,\n",
       "  1.7481048107147217,\n",
       "  6.40861701965332],\n",
       " 'label': 7}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_json = {\n",
    "    \"scale\": 10**-40,\n",
    "    \"out\": y.flatten().tolist(),\n",
    "    \"label\": int(y.argmax())\n",
    "}\n",
    "out_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mnist_latest_input.json\", \"w\") as f:\n",
    "    json.dump(in_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mnist_latest_output.json\", \"w\") as f:\n",
    "    json.dump(out_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11280bdb37aa6bc5d4cf1e4de756386eb1f9eecd8dcdefa77636dfac7be2370d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 ('tf24')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
